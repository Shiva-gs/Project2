{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import library \n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tripadviser url/retrieve page with the requests module/parse with 'html.parser\n",
    "url_ny_restaurant = 'https://www.yelp.com/search?find_desc=Restaurants&find_loc=New%20York%2C%20NY&ns=1&sortby=recommended'\n",
    "# url_ny_bars = 'https://www.yelp.com/search?find_desc=Bars&find_loc=New+York%2C+NY'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(soup.prettify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usea funciton to get all the data from one page\n",
    "def souping(url):    \n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.text,'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_soup = souping(url_ny_restaurant)\n",
    "# ny_soup_bars = souping(url_ny_bars)\n",
    "#print(ny_soup_bars.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name results are returned as an iterable list\n",
    "ny_name = ny_soup.find_all('a', class_ = 'lemon--a__373c0__IEZFH link__373c0__29943 link-color--blue-dark__373c0__1mhJo link-size--inherit__373c0__2JXk5')\n",
    "# ny_name_bars = ny_soup_bars('a', class_ = 'lemon--a__373c0__IEZFH link__373c0__29943 link-color--blue-dark__373c0__1mhJo link-size--inherit__373c0__2JXk5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ny_name_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the name\n",
    "#store the top 30 attraction into a list\n",
    "\n",
    "def find_title(rstrnt_name):\n",
    "    title_list = []\n",
    "    for name in rstrnt_name:\n",
    "        try:\n",
    "            title = name.text\n",
    "\n",
    "            if(title):\n",
    "\n",
    "                title_list.append(title)\n",
    "        except AttributeError as e:\n",
    "            print(e)\n",
    "\n",
    "    return title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pizzette', 'read more', 'Los Tres Chiflados', 'read more', 'Jajaja', 'read more', 'The Dead Rabbit', 'read more', 'The Up & Up', 'read more', 'Attaboy', 'read more', 'Apothèke', 'read more', 'The Binc', 'read more', 'Nitecap', 'read more', 'The Ship', 'read more', 'Botanica Bar', 'read more', 'Hidden Lane', 'read more', 'Livingston Manor', 'read more', 'The Belfry', 'read more', 'Rooftop 93', 'read more', 'BED STUY Barb’s', 'read more', 'Gowanus Gardens', 'read more', 'Please Don’t Tell', 'read more', 'District Social', 'read more', 'A+ Roof Bar', 'read more', 'Boilery', 'read more', 'Whiskey Tavern', 'read more', '1 Rooftop Garden & Bar', 'read more', 'The Lost Lady', 'read more', 'The Maze', 'read more', 'Fresh Kills Bar', 'read more', 'Angel’s Share', 'read more', 'The Library', 'read more', 'FREEHOLD', 'read more', 'Someday Bar', 'read more', 'The Flamingo', 'read more', 'More Topics', 'Some Data By Acxiom']\n"
     ]
    }
   ],
   "source": [
    "ny_title = find_title(ny_name)\n",
    "# ny_title_bars = find_title(ny_name_bars)\n",
    "# print(ny_title_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(titles):\n",
    "    cleaned_list = []\n",
    "    for title in titles:\n",
    "        if title !=\"read more\":\n",
    "            cleaned_list.append(title)\n",
    "    return cleaned_list[1:31]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amélie', 'Upstate', 'LoveMama', 'Burger & Lobster', 'Thai Villa', 'Aunt Jake’s', 'Ipanema Restaurant', 'Bogota Latin Bistro', 'Barn Joo', 'Uglyduckling', 'Paesano of Mulberry Street', 'Juliana’s Pizza', 'Salt + Charcoal', 'Boucherie West Village', 'Gelso & Grand', 'Barn Joo 35', 'Pig and Khao', 'Joe’s Shanghai', 'nonono', 'Chama Mama', 'Atrium Dumbo', 'Alta', 'Somtum Der', 'Balzem', 'Antica Ristorante', 'Bea', 'The MasalaWala', 'Fishmarket Restaurant', 'Toloache 50', '1803']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_title_cleaned = clean_title(ny_title) \n",
    "ny_bars_title_cleaned = clean_title(ny_title_bars)\n",
    "print(ny_title_cleaned)\n",
    "len(ny_title_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_finder(city_soup):\n",
    "\n",
    "    # find add\n",
    "    adds = city_soup.find_all('p', class_=\"lemon--p__373c0__3Qnnj text__373c0__2pB8f text-color--normal__373c0__K_MKN text-align--right__373c0__3ARv7\")\n",
    "    #print(result_review)\n",
    "    add_list = []\n",
    "    for add in adds:\n",
    "        add_list.append(add.text)\n",
    "\n",
    "    \n",
    "    return add_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_add = add_finder(ny_soup)\n",
    "# ny_bars_add = add_finder(ny_soup_bars)\n",
    "# ny_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the add from the list\n",
    "def add_cleaner(adds):\n",
    "    add_list = adds[1::]\n",
    "    \n",
    "    add_cleaned = []\n",
    "    for i in range(1,31):\n",
    "        add_cleaned.append(add_list[3*i+1])\n",
    "\n",
    "    return add_cleaned\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['22 W 8th St',\n",
       " '95 1st Ave',\n",
       " '174 2nd Ave',\n",
       " '39 W 19th St',\n",
       " '5 E 19th St',\n",
       " '149 Mulberry St',\n",
       " '43 W 46th St',\n",
       " '141 5th Ave',\n",
       " '35 Union Sq W',\n",
       " '166 Smith St',\n",
       " '136 Mulberry St',\n",
       " '19 Old Fulton St',\n",
       " '171 Grand St',\n",
       " '99 7th Ave S',\n",
       " '186 Grand St',\n",
       " '34 W 35th St',\n",
       " '68 Clinton St',\n",
       " '9 Pell St',\n",
       " '118 Madison Ave',\n",
       " '149 W 14th St',\n",
       " '15 Main St',\n",
       " '64 W 10th St',\n",
       " '85 Ave A',\n",
       " '202 Mott St',\n",
       " '8 Stone St',\n",
       " '403 W 43rd St',\n",
       " '179 Essex St',\n",
       " '111 South St',\n",
       " '251 West 50th St',\n",
       " '82 Reade St']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ny_add_clean = add_cleaner(ny_add)\n",
    "# ny_bars_add_clean = add_cleaner(ny_bars_add)\n",
    "print(len(ny_add_clean))\n",
    "ny_add_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def review_finder(city_soup):  \n",
    "    # used the same methdo to obtain price for each restaurant \n",
    "    result_review = city_soup.find_all('span', class_=\"lemon--span__373c0__3997G text__373c0__2pB8f reviewCount__373c0__2r4xT text-color--mid__373c0__3G312 text-align--left__373c0__2pnx_\")\n",
    "    #print(result_review)\n",
    "    review_list = []\n",
    "    for review in result_review:\n",
    "        review_list.append(review.text)\n",
    "\n",
    "    return review_list[1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_restaurant_reviews = review_finder(ny_soup)\n",
    "ny_bars_reviews = review_finder(ny_soup_bars)\n",
    "print(len(ny_bars_reviews))\n",
    "ny_bars_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store data to a object export to mongodb later\n",
    "ny_restaurant = {\n",
    "    \"name\":ny_title_cleaned,\n",
    "    \"reviews\":ny_restaurant_reviews,\n",
    "    \"address\":ny_add_clean\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('ny_restaurant.json', 'w') as ny:\n",
    "#     json.dump(ny_restaurant, ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
